\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{Newtons Method Practice Problems}
\author{Swesan Pathmanathan}
\date{December 2025}

\begin{document}

\maketitle

\section*{Problems}

% ------------------------------------------
% NEWTON'S METHOD EXAM-STYLE PROBLEMS
% ------------------------------------------

\subsection*{Problem 1 — Deriving Newton’s Method}
Starting from the Taylor expansion of \(f\) around the current iterate \(x_n\),  
derive the Newton iteration formula
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}.
\]

\subsection*{Problem 2 — Newton Iteration for a Square Root}
We wish to compute \(\sqrt{a}\) for some \(a > 0\).

(a) Define a function \(f(x)\) whose root is \(\sqrt{a}\).  
(b) Apply Newton’s method to derive an explicit iteration formula for \(x_{n+1}\).  
(c) For \(a = 10\) and \(x_0 = 4\), compute \(x_1\) and \(x_2\).

\subsection*{Problem 3 — Division Without Division}
To compute \(a/b\) without using division, we compute the reciprocal \(1/b\) using Newton’s method.

(a) Define a scalar function \(f(x)\) whose root is \(x = 1/b\).  
(b) Derive the Newton iteration formula for approximating \(1/b\).  
(c) Using \(b = 5\) and \(x_0 = 0.2\), compute \(x_1\) and \(x_2\).

\subsection*{Problem 4 — Convergence Rate}
Let \(r\) be a simple root of \(f\) (i.e., \(f(r)=0\), \(f'(r) \neq 0\)).  
Let \(e_n = r - x_n\).

(a) Using the Newton error expression, show that the error satisfies
\[
|e_{n+1}| \le C |e_n|^2
\]
for some constant \(C > 0\).

(b) Explain what “quadratic convergence” means in practical terms (e.g., number of correct digits gained per iteration).

\subsection*{Problem 5 — Newton Failure with Multiple Roots}
Consider 
\[
f(x) = (x - 1)^2.
\]

(a) Compute \(f'(x)\).  
(b) Write the Newton update formula \(x_{n+1}\).  
(c) Show that Newton’s method converges **linearly**, not quadratically, for this function.  
(d) Write the modified Newton method that restores quadratic convergence.

\subsection*{Problem 6 — Secant Method}
When \(f'(x)\) is not available, we approximate it using:
\[
f'(x_n) \approx \frac{f(x_n) - f(x_{n-1})}{x_n - x_{n-1}}.
\]

(a) Derive the secant iteration formula
\[
x_{n+1} = x_n - f(x_n)\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}.
\]

(b) Explain why the secant method has order of convergence \(\alpha \approx 1.618\).  
(c) Compare the secant method to Newton’s method in terms of:  
   • derivative use,  
   • speed,  
   • robustness.

\subsection*{Problem 7 — Newton’s Method for Systems}
Consider the nonlinear system
\[
F(x) =
\begin{pmatrix}
x_1^2 + x_2^2 - 9 \\
x_1^2 - x_2 - 1
\end{pmatrix}
= 0.
\]

(a) Compute the Jacobian matrix \(F'(x)\).  
(b) Write the Newton update step:
\[
F'(x^{(k)}) s^{(k)} = -F(x^{(k)}), \qquad x^{(k+1)} = x^{(k)} + s^{(k)}.
\]
(c) Using the initial guess \(x^{(0)} = (3, 1)^T\), compute the Newton correction \(s^{(0)}\) by solving the linear system, and then compute \(x^{(1)}\).

% ---------------------------------------------------
% WEEK 09 TUTORIAL PROBLEMS (NONLINEAR EQUATIONS)
% ---------------------------------------------------

\subsection*{Problem 8 — Bisection Method Step Count}
For the bisection method applied to a continuous function \(f\) on \([a,b]\) with
\(f(a)f(b) < 0\), the error after \(n\) steps satisfies
\[
|x_n - r| \le \frac{b-a}{2^{\,n+1}}.
\]

Given the interval \([0.1, 1]\) and error tolerance
\[
|x_n - r| \le 0.5 \times 10^{-8},
\]
determine the minimum number of bisection steps required.

\subsection*{Problem 9 — Newton’s Method for Reciprocal Square Root}
We wish to compute
\[
x = \frac{1}{\sqrt{a}}, \qquad a > 0.
\]

(a) Define a function \(f(x)\) whose root is \(1/\sqrt{a}\).  
(b) Derive the Newton iteration formula for approximating \(1/\sqrt{a}\).  
(c) Using \(a = 5\), compute \(x_1\) and \(x_2\) when the initial guess is \(x_0 = 0.5\).  
(d) Explain why Newton’s method *cycles* if \(x_0 = 1\).

\subsection*{Problem 10 — Newton’s Method on \(x - e^{-x}\)}
Consider the function
\[
f(x) = x - e^{-x}.
\]

(a) Compute the Newton iteration formula.  
(b) Without using a computer, explain whether Newton’s method is likely to converge from a large initial guess such as \(x_0 = 20\).  
(c) Explain the expected qualitative behavior of the iterates.

\subsection*{Problem 11 — Kepler’s Equation (Conceptual Newton Setup)}
Kepler’s equation for the eccentric anomaly \(E\) is
\[
M = E - e\sin E,
\]
where \(M = 24.85109^\circ\) and \(e=0.1\).

(a) Write the residual function \(K(E)\) whose root gives the solution.  
(b) Compute \(K'(E)\).  
(c) Write the Newton iteration formula.  
(No numeric iteration required.)

\subsection*{Problem 12 — Nonlinear System and Jacobian Singularity}
Consider the system
\[
\begin{cases}
x - y = 0, \\
(x - y)^2 + (y - 1)^2 = 0.
\end{cases}
\]

(a) Write the system in vector form \(F(u)=0\), where \(u=(x,y)^\top\).  
(b) Compute the Jacobian matrix \(F'(x,y)\).  
(c) Determine all points where the Jacobian is singular.  
(d) Explain why Newton’s method fails or converges slowly if the Jacobian becomes singular or nearly singular.

% ---------------------------------------------------
% ASSIGNMENT 4 — NEWTON METHOD PROBLEMS (EXAM VERSION)
% ---------------------------------------------------

\subsection*{Problem 13 — Newton with Finite-Difference Derivative}
We want to solve \(f(x)=0\) using Newton’s method, but the derivative is not available.
Instead, approximate it using the forward-difference formula:
\[
f'(x) \approx \frac{f(x+h)-f(x)}{h}.
\]

(a) Derive the finite-difference Newton update formula:
\[
x_{k+1} = x_k - 
\frac{f(x_k)}{\frac{f(x_k + h)-f(x_k)}{h}}.
\]

(b) Let 
\[
f(x)=e^{-x}(x^3 - 4x + 1) + 0.2\cos(3x).
\]
Using \(h=10^{-4}\) and \(x_0 = -1.5\), compute one Newton iteration \(x_1\) by hand.

(c) Explain how the choice of \(h\) affects:
- accuracy of the derivative approximation,  
- convergence speed,  
- when Newton may fail.

% ---------------------------------------------------

\subsection*{Problem 14 — Newton for the Annuity Equation}
The annuity equation relating present value \(A\), payment \(P\), interest rate \(r\),  
and number of payments \(n\) is:
\[
A = \frac{P}{r} (1 - (1+r)^{-n}).
\]

(a) Rearrange this into a root-finding problem \(f(r)=0\).

(b) Derive Newton’s method for solving for \(r\).

(c) For \(A=10000\), \(P=200\), \(n=240\), choose a reasonable \(r_0\)  
and perform two Newton iterations.

% ---------------------------------------------------

\subsection*{Problem 15 — Newton on \boldmath$x^5 - x^3 - 4x$}
Consider the equation:
\[
x^5 - x^3 - 4x = 0.
\]

(a) Write the Newton iteration formula.

(b) Describe the behavior of the Newton iterates when \(x_0 = 1\).  
Does the method converge? Why or why not?

(c) Explain why the behavior changes drastically if \(x_0 = 1 + 10^{-10}\).  
Does Newton converge from this perturbed initial value?

% ---------------------------------------------------

\subsection*{Problem 16 — Newton’s Method for a Nonlinear System}
Consider the nonlinear system:
\[
\begin{cases}
x_1 + x_2(x_2(5 - x_2)-2)=13,\\
x_1 + x_2(x_2(1 + x_2)-14)=29,
\end{cases}
\]
starting from \((x_1,x_2)=(15,-2)\).

(a) Write the system in vector form \(F(x)=0\).

(b) Compute the Jacobian matrix \(F'(x)\).

(c) Write the Newton update step:
\[
F'(x^{(k)}) s^{(k)} = -F(x^{(k)}), \qquad x^{(k+1)} = x^{(k)} + s^{(k)}.
\]

(d) Compute the Newton correction \(s^{(0)}\) and the updated iterate \(x^{(1)}\)
by solving the linear system manually.

(e) Discuss one reason why Newton might fail or converge slowly for this system.



\section*{Solutions}

\subsection*{Solution 1}
From Taylor expansion:
\[
f(r) = f(x_n) + f'(x_n)(r - x_n) + O((r-x_n)^2).
\]
Since \(f(r)=0\), neglecting higher-order terms:
\[
0 \approx f(x_n) + f'(x_n)(x_{n+1} - x_n).
\]
Solve for \(x_{n+1}\):
\[
\boxed{
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
}
\]

\subsection*{Solution 2}
(a) Let \(f(x) = x^2 - a\).  
(b)
\[
x_{n+1} = x_n - \frac{x_n^2 - a}{2x_n}
= \frac{1}{2}\left(x_n + \frac{a}{x_n}\right).
\]

(c) For \(a=10\), \(x_0=4\):

\[
x_1 = \frac{1}{2}\left(4 + \frac{10}{4}\right) = \frac{1}{2}(4 + 2.5) = 3.25.
\]

\[
x_2 = \frac{1}{2}\left(3.25 + \frac{10}{3.25}\right)
= \frac{1}{2}(3.25 + 3.0769)
= 3.16345.
\]

\subsection*{Solution 3}
(a) Solve:
\[
f(x) = \frac{1}{x} - b = 0.
\]

(b)
\[
x_{n+1} = x_n - \frac{1/x_n - b}{-1/x_n^2}
= x_n(2 - b x_n).
\]

(c) For \(b = 5\), \(x_0 = 0.2\):

\[
x_1 = 0.2(2 - 5 \cdot 0.2) = 0.2(2 - 1) = 0.2.
\]
\[
x_2 = 0.2(2 - 5 \cdot 0.2) = 0.2.
\]

Correct reciprocal is \(1/5 = 0.2\), so the initial guess was exact.

\subsection*{Solution 4}
(a)
From Newton error analysis:
\[
e_{n+1} = -\frac{f''(\xi)}{2f'(x_n)} e_n^2,
\]
so
\[
|e_{n+1}| \le C |e_n|^2.
\]

(b) Quadratic convergence means:
- each step **roughly squares the error**,  
- number of correct digits doubles each iteration (once close enough).

\subsection*{Solution 5}
(a)
\[
f'(x) = 2(x - 1).
\]

(b)
\[
x_{n+1} = x_n - \frac{(x_n - 1)^2}{2(x_n - 1)}
= x_n - \frac{x_n - 1}{2}
= \frac{1}{2}(x_n + 1).
\]

(c) Error:
\[
e_{n+1} = \frac{1}{2} e_n,
\]
so convergence is linear.

(d) Modified Newton with multiplicity \(m=2\):
\[
x_{n+1} = x_n - 2\frac{f(x_n)}{f'(x_n)}.
\]

\subsection*{Solution 6}
(a)
Replace \(f'(x_n)\) in Newton’s method with a finite difference:
\[
x_{n+1} = x_n - f(x_n)
\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}.
\]

(b) It can be shown the order is:
\[
\alpha = \frac{1 + \sqrt{5}}{2} \approx 1.618.
\]

(c)
- Newton: fast, needs derivative  
- Secant: slower, no derivative needed  
- Secant: more robust, cheaper per iteration

\subsection*{Solution 7}
(a)
\[
F'(x) =
\begin{pmatrix}
2x_1 & 2x_2 \\
2x_1 & -1
\end{pmatrix}.
\]

(b)
\[
F'(x^{(k)}) s^{(k)} = -F(x^{(k)}),
\qquad x^{(k+1)} = x^{(k)} + s^{(k)}.
\]

(c)
At \(x^{(0)} = (3, 1)^T\):

\[
F(x^{(0)}) =
\begin{pmatrix}
3^2 + 1^2 - 9 \\
3^2 - 1 - 1
\end{pmatrix}
=
\begin{pmatrix}
1 \\ 7
\end{pmatrix}.
\]

Jacobian:
\[
F'(x^{(0)}) =
\begin{pmatrix}
6 & 2 \\
6 & -1
\end{pmatrix}.
\]

Solve:
\[
\begin{pmatrix}
6 & 2 \\
6 & -1
\end{pmatrix}
s^{(0)} =
-
\begin{pmatrix}
1 \\ 7
\end{pmatrix}.
\]

Solution:
\[
s^{(0)} =
\begin{pmatrix}
-1 \\
2.5
\end{pmatrix}.
\]

Thus:
\[
x^{(1)} = x^{(0)} + s^{(0)}
=
\begin{pmatrix}
3 \\ 1
\end{pmatrix}
+
\begin{pmatrix}
-1 \\ 2.5
\end{pmatrix}
=
\begin{pmatrix}
2 \\ 3.5
\end{pmatrix}.
\]

\subsection*{Solution 8}
We require
\[
\frac{b-a}{2^{\,n+1}} \le 0.5\times 10^{-8}.
\]
With \(a = 0.1\), \(b = 1\):
\[
\frac{0.9}{2^{\,n+1}} \le 0.5\times 10^{-8}
\quad\Longrightarrow\quad
2^{\,n+1} \ge \frac{0.9}{0.5\times 10^{-8}}.
\]
Thus:
\[
2^{\,n+1} \ge 1.8\times 10^{8}.
\]
Taking base-2 logarithm:
\[
n+1 \ge \log_2(1.8\times 10^{8}) \approx 28.1.
\]
Hence the smallest integer satisfying this is
\[
\boxed{n = 27}.
\]

\subsection*{Solution 9}
(a) We want \(x = 1/\sqrt{a}\), so
\[
f(x) = \frac{1}{x^2} - a.
\]

(b) Compute derivative:
\[
f'(x) = -2x^{-3}.
\]
Newton update:
\[
x_{k+1}
= x_k - \frac{x_k^{-2} - a}{-2 x_k^{-3}}
= x_k + \frac{x_k - a x_k^3}{2}
= x_k\left(1.5 - 0.5 a x_k^2\right).
\]

(c) For \(a = 5\), \(x_0 = 0.5\):
\[
x_1 = 0.5\left(1.5 - 0.5\cdot 5\cdot 0.5^2\right)
= 0.5(1.5 - 0.625)
= 0.4375.
\]
\[
x_2 = 0.4375\left(1.5 - 0.5\cdot 5\cdot 0.4375^2\right)
\approx 0.4375(1.5 - 0.4785)
\approx 0.4467.
\]

(d) If \(x_0 = 1\):
\[
x_1 = 1(1.5 - 0.5a\cdot 1^2) = 1(1.5 - 0.5a).
\]
For \(a=5\):
\[
x_1 = 1(1.5 - 2.5) = -1.
\]
\[
x_2 = -1(1.5 - 2.5) = 1.
\]
Thus:
\[
1 \rightarrow -1 \rightarrow 1 \rightarrow -1 \rightarrow \dots
\]
The method **cycles** and fails to converge.

\subsection*{Solution 10}
(a) For
\[
f(x)=x-e^{-x},
\quad f'(x)=1+e^{-x}.
\]
Newton update:
\[
x_{k+1}
= x_k - \frac{x_k - e^{-x_k}}{1 + e^{-x_k}}.
\]

(b) For very large \(x_k\), \(e^{-x_k}\) is extremely small.  
Then:
\[
x_{k+1} \approx x_k - \frac{x_k}{1} = 0.
\]
So Newton jumps rapidly back toward 0.

(c) Expected behavior:
- From large \(x_0\): first step lands near 0  
- Then method behaves normally near the root  
- Converges safely

\subsection*{Solution 11}
(a)
\[
K(E)=M - E + e\sin E.
\]

(b)
\[
K'(E)= -1 + e\cos E.
\]

(c) Newton iteration:
\[
E_{k+1}
= E_k - \frac{M - E_k + e\sin E_k}{-1 + e\cos E_k}.
\]

\subsection*{Solution 12}
(a)
\[
u=
\begin{pmatrix} x \\ y \end{pmatrix},
\qquad
F(u)=
\begin{pmatrix}
x - y \\
(x-y)^2 + (y-1)^2
\end{pmatrix}.
\]

(b)
\[
F'(x,y)=
\begin{pmatrix}
1 & -1 \\
2(x-y) & -2(x-y) + 2(y-1)
\end{pmatrix}.
\]

(c) Singular when determinant = 0:
\[
\det F'(x,y)=2(y-1)=0 \quad\Longrightarrow\quad y=1.
\]

(d) Newton fails when \(F'(u)\) is singular or nearly singular because:
- cannot solve the linear system for the Newton step,  
- near-singular Jacobian → very large or unstable steps,  
- convergence becomes slow or stops.

Thus, initial guesses with \(y=1\) cause immediate failure, and guesses approaching \(y\approx 1\) converge slowly.

\subsection*{Solution 13}

(a)
\[
x_{k+1} = x_k - 
\frac{f(x_k)}{(f(x_k+h)-f(x_k))/h}
= x_k - h \frac{f(x_k)}{f(x_k+h)-f(x_k)}.
\]

(b)
Let \(f(x)=e^{-x}(x^3 - 4x + 1)+0.2\cos(3x)\),  
\(x_0=-1.5\), \(h=10^{-4}\).

Compute:
\[
f(x_0) \approx f(-1.5), \quad  
f(x_0+h)= f(-1.4999).
\]

Using a calculator (values shown to 6 decimals):
\[
f(-1.5)=0.585000,
\qquad
f(-1.4999)=0.584942.
\]

Then:
\[
x_1 = x_0 - h\frac{f(x_0)}{f(x_0+h)-f(x_0)}
= -1.5 - 10^{-4}\frac{0.585000}{0.584942 - 0.585000}
\]

Denominator:
\[
0.584942 - 0.585000 = -0.000058.
\]

Thus:
\[
x_1 \approx -1.5 - 10^{-4}\left(\frac{0.585000}{-0.000058}\right)
\approx -1.5 + 1.0086
= -0.4914.
\]

(c)

- Too **large** \(h\): inaccurate derivative → slow convergence  
- Too **small** \(h\): subtractive cancellation → numerical noise  
- Optimal \(h\): typically \(10^{-6}\) to \(10^{-8}\)  
- If derivative estimate becomes unstable, Newton diverges or oscillates

% ---------------------------------------------------

\subsection*{Solution 14}

(a)
Rearrange:
\[
A r = P(1-(1+r)^{-n})
\]
\[
f(r)=A r - P(1-(1+r)^{-n}) = 0.
\]

(b)
\[
f'(r)=A - P(-n)(1+r)^{-n-1}.
\]

Newton update:
\[
r_{k+1}=r_k - \frac{A r_k - P(1-(1+r_k)^{-n})}{A + Pn(1+r_k)^{-n-1}}.
\]

(c)
Use \(A=10000\), \(P=200\), \(n=240\).

A reasonable starting guess is \(r_0=0.01\) (≈1% per period).

Compute:
\[
f(r_0)=100 - 200(1-(1.01)^{-240}).
\]

\((1.01)^{-240}\approx 0.0901\).

Thus:
\[
f(r_0)=100 - 200(1-0.0901)=100 - 200(0.9099)=100 - 181.98=-81.98.
\]

Derivative:
\[
f'(r_0)=10000 + 200\cdot 240 (1.01)^{-241}
\approx 10000 + 48000(0.0892)
\approx 10000 + 4282=14282.
\]

Newton:
\[
r_1 = 0.01 - \frac{-81.98}{14282}=0.01 + 0.00574=0.01574.
\]

Second iteration:
Compute \(f(r_1)\approx\) small (omitted here for space), giving:

\[
r_2 \approx 0.0171.
\]

Final approximate rate:
\[
\boxed{r \approx 0.017}.
\]

% ---------------------------------------------------

\subsection*{Solution 15}

(a)
\[
f(x)=x^5 - x^3 - 4x,
\quad
f'(x)=5x^4 - 3x^2 - 4.
\]

Newton:
\[
x_{k+1}=x_k - \frac{x_k^5 - x_k^3 - 4x_k}{5x_k^4 - 3x_k^2 -4}.
\]

(b)
At \(x_0=1\):
\[
f(1)=1 -1 -4 = -4,
\]
\[
f'(1)=5 -3 -4 = -2.
\]

Thus:
\[
x_1 = 1 - \frac{-4}{-2}= -1.
\]

Then:
\[
x_2 = -1 - \frac{-(-1)^5 + (-1)^3 + 4}{5 - 3 -4}
= -1 - \frac{4}{-2}=1.
\]

The method **cycles**:  
\[
1\to -1\to 1\to -1\to \dots
\]

(c)
Take \(x_0=1+10^{-10}\).

Then numerator and denominator differ slightly, enough to break symmetry.  
Newton escapes the unstable cycle and moves toward the nearest real root (≈0).

Yes — Newton converges from \(1+10^{-10}\).

% ---------------------------------------------------

\subsection*{Solution 16}

(a)
\[
F(x)=
\begin{pmatrix}
x_1 + x_2(x_2(5-x_2)-2)-13\\[4pt]
x_1 + x_2(x_2(1+x_2)-14)-29
\end{pmatrix}.
\]

(b)  
Partial derivatives:

\[
\frac{\partial F_1}{\partial x_1}=1,\quad
\frac{\partial F_1}{\partial x_2}= (5-3x_2)x_2 -2.
\]

\[
\frac{\partial F_2}{\partial x_1}=1,\quad
\frac{\partial F_2}{\partial x_2}= (1+3x_2)x_2 -14.
\]

Thus:
\[
F'(x)=
\begin{pmatrix}
1 & (5-3x_2)x_2 -2\\
1 & (1+3x_2)x_2 -14
\end{pmatrix}.
\]

(c)
\[
F'(x^{(k)}) s^{(k)}=-F(x^{(k)}),\qquad  
x^{(k+1)}=x^{(k)}+s^{(k)}.
\]

(d)  
At \(x^{(0)}=(15,-2)\):

\[
F(x^{(0)})=
\begin{pmatrix}
15 + (-2)(-2(5+2)-2)-13\\
15 + (-2)(-2(1-2)-14)-29
\end{pmatrix}
=
\begin{pmatrix}
5\\
-1
\end{pmatrix}.
\]

Jacobian:
\[
F'(x^{(0)})=
\begin{pmatrix}
1 & (5+6)(-2)-2\\
1 & (1-6)(-2)-14
\end{pmatrix}
=
\begin{pmatrix}
1 & -16\\
1 & -4
\end{pmatrix}.
\]

Solve:
\[
\begin{pmatrix}
1 & -16\\
1 & -4
\end{pmatrix}
s=
-
\begin{pmatrix}
5\\
-1
\end{pmatrix}.
\]

Subtract rows:

Row2 – Row1:
\[
(0,\;12)s = (4)
\Rightarrow s_2=\tfrac{1}{3}.
\]

Then:
\[
s_1 = -5 + 16(\tfrac{1}{3})
= -5 + \tfrac{16}{3}
= \tfrac{1}{3}.
\]

Thus:
\[
s^{(0)}=
\begin{pmatrix}
1/3\\
1/3
\end{pmatrix}.
\]

\[
x^{(1)}=
\begin{pmatrix}
15 + 1/3\\
-2 + 1/3
\end{pmatrix}
=
\begin{pmatrix}
15.3333\\
-1.6667
\end{pmatrix}.
\]

(e)
Jacobian can become nearly singular if its columns nearly align:  
→ large Newton steps → instability → slow or divergent convergence.


\end{document}
